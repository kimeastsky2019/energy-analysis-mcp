{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"kLkE_JWykkPY"},"outputs":[],"source":["import numpy as np\n","\n","\n","def readucr(filename):\n","    data = np.loadtxt(filename, delimiter=\"\\t\")\n","    y = data[:, 0]\n","    x = data[:, 1:]\n","    return x, y.astype(int)\n","\n","\n","root_url = \"https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/\"\n","\n","x_train, y_train = readucr(root_url + \"FordA_TRAIN.tsv\")\n","x_test, y_test = readucr(root_url + \"FordA_TEST.tsv\")\n","\n","x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n","x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n","\n","n_classes = len(np.unique(y_train))\n","\n","idx = np.random.permutation(len(x_train))\n","x_train = x_train[idx]\n","y_train = y_train[idx]\n","\n","y_train[y_train == -1] = 0\n","y_test[y_test == -1] = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1667114466418,"user":{"displayName":"Jaemin Lee","userId":"08805103255937307638"},"user_tz":-540},"id":"88FHjLOXNJnt","outputId":"d6eaee63-2af5-4c7c-d474-00b61cba5461"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3601, 500, 1)"]},"metadata":{},"execution_count":2}],"source":["x_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1667114471931,"user":{"displayName":"Jaemin Lee","userId":"08805103255937307638"},"user_tz":-540},"id":"Lt8o8Si9NNsD","outputId":"e65d0a55-3bb4-4172-83bf-0beab2f29ead"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3601,)"]},"metadata":{},"execution_count":4}],"source":["y_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p51HrizjkkPa"},"outputs":[],"source":["from tensorflow import keras\n","from tensorflow.keras import layers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"18s2AmZmkkPb"},"outputs":[],"source":["def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n","    # Normalization and Attention\n","    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n","    x = layers.MultiHeadAttention(\n","        key_dim=head_size, num_heads=num_heads, dropout=dropout\n","    )(x, x) # self-attn.\n","    x = layers.Dropout(dropout)(x)\n","    res = x + inputs\n","\n","    # Feed Forward Part\n","    x = layers.LayerNormalization(epsilon=1e-6)(res)\n","    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n","    x = layers.Dropout(dropout)(x)\n","    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n","    return x + res\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-tzdVWitkkPc"},"outputs":[],"source":["\n","def build_model(\n","    input_shape,\n","    head_size,\n","    num_heads,\n","    ff_dim,\n","    num_transformer_blocks,\n","    mlp_units,\n","    dropout=0,\n","    mlp_dropout=0,\n","):\n","    inputs = keras.Input(shape=input_shape)\n","    x = inputs\n","    for _ in range(num_transformer_blocks):\n","        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n","\n","    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n","    for dim in mlp_units:\n","        x = layers.Dense(dim, activation=\"relu\")(x)\n","        x = layers.Dropout(mlp_dropout)(x)\n","    outputs = layers.Dense(n_classes, activation=\"softmax\")(x)\n","    return keras.Model(inputs, outputs)\n"]},{"cell_type":"markdown","metadata":{"id":"ZIiMfz2fkkPc"},"source":["## Train and evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"1D7EAgEqkkPd","outputId":"26d8fff1-c46b-47fb-c07f-3a4caf8ef0f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 500, 1)]     0           []                               \n","                                                                                                  \n"," layer_normalization (LayerNorm  (None, 500, 1)      2           ['input_1[0][0]']                \n"," alization)                                                                                       \n","                                                                                                  \n"," multi_head_attention (MultiHea  (None, 500, 1)      7169        ['layer_normalization[0][0]',    \n"," dAttention)                                                      'layer_normalization[0][0]']    \n","                                                                                                  \n"," dropout (Dropout)              (None, 500, 1)       0           ['multi_head_attention[0][0]']   \n","                                                                                                  \n"," tf.__operators__.add (TFOpLamb  (None, 500, 1)      0           ['dropout[0][0]',                \n"," da)                                                              'input_1[0][0]']                \n","                                                                                                  \n"," layer_normalization_1 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add[0][0]']   \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv1d (Conv1D)                (None, 500, 4)       8           ['layer_normalization_1[0][0]']  \n","                                                                                                  \n"," dropout_1 (Dropout)            (None, 500, 4)       0           ['conv1d[0][0]']                 \n","                                                                                                  \n"," conv1d_1 (Conv1D)              (None, 500, 1)       5           ['dropout_1[0][0]']              \n","                                                                                                  \n"," tf.__operators__.add_1 (TFOpLa  (None, 500, 1)      0           ['conv1d_1[0][0]',               \n"," mbda)                                                            'tf.__operators__.add[0][0]']   \n","                                                                                                  \n"," layer_normalization_2 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_1[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," multi_head_attention_1 (MultiH  (None, 500, 1)      7169        ['layer_normalization_2[0][0]',  \n"," eadAttention)                                                    'layer_normalization_2[0][0]']  \n","                                                                                                  \n"," dropout_2 (Dropout)            (None, 500, 1)       0           ['multi_head_attention_1[0][0]'] \n","                                                                                                  \n"," tf.__operators__.add_2 (TFOpLa  (None, 500, 1)      0           ['dropout_2[0][0]',              \n"," mbda)                                                            'tf.__operators__.add_1[0][0]'] \n","                                                                                                  \n"," layer_normalization_3 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_2[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv1d_2 (Conv1D)              (None, 500, 4)       8           ['layer_normalization_3[0][0]']  \n","                                                                                                  \n"," dropout_3 (Dropout)            (None, 500, 4)       0           ['conv1d_2[0][0]']               \n","                                                                                                  \n"," conv1d_3 (Conv1D)              (None, 500, 1)       5           ['dropout_3[0][0]']              \n","                                                                                                  \n"," tf.__operators__.add_3 (TFOpLa  (None, 500, 1)      0           ['conv1d_3[0][0]',               \n"," mbda)                                                            'tf.__operators__.add_2[0][0]'] \n","                                                                                                  \n"," layer_normalization_4 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_3[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," multi_head_attention_2 (MultiH  (None, 500, 1)      7169        ['layer_normalization_4[0][0]',  \n"," eadAttention)                                                    'layer_normalization_4[0][0]']  \n","                                                                                                  \n"," dropout_4 (Dropout)            (None, 500, 1)       0           ['multi_head_attention_2[0][0]'] \n","                                                                                                  \n"," tf.__operators__.add_4 (TFOpLa  (None, 500, 1)      0           ['dropout_4[0][0]',              \n"," mbda)                                                            'tf.__operators__.add_3[0][0]'] \n","                                                                                                  \n"," layer_normalization_5 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_4[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv1d_4 (Conv1D)              (None, 500, 4)       8           ['layer_normalization_5[0][0]']  \n","                                                                                                  \n"," dropout_5 (Dropout)            (None, 500, 4)       0           ['conv1d_4[0][0]']               \n","                                                                                                  \n"," conv1d_5 (Conv1D)              (None, 500, 1)       5           ['dropout_5[0][0]']              \n","                                                                                                  \n"," tf.__operators__.add_5 (TFOpLa  (None, 500, 1)      0           ['conv1d_5[0][0]',               \n"," mbda)                                                            'tf.__operators__.add_4[0][0]'] \n","                                                                                                  \n"," layer_normalization_6 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_5[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," multi_head_attention_3 (MultiH  (None, 500, 1)      7169        ['layer_normalization_6[0][0]',  \n"," eadAttention)                                                    'layer_normalization_6[0][0]']  \n","                                                                                                  \n"," dropout_6 (Dropout)            (None, 500, 1)       0           ['multi_head_attention_3[0][0]'] \n","                                                                                                  \n"," tf.__operators__.add_6 (TFOpLa  (None, 500, 1)      0           ['dropout_6[0][0]',              \n"," mbda)                                                            'tf.__operators__.add_5[0][0]'] \n","                                                                                                  \n"," layer_normalization_7 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_6[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv1d_6 (Conv1D)              (None, 500, 4)       8           ['layer_normalization_7[0][0]']  \n","                                                                                                  \n"," dropout_7 (Dropout)            (None, 500, 4)       0           ['conv1d_6[0][0]']               \n","                                                                                                  \n"," conv1d_7 (Conv1D)              (None, 500, 1)       5           ['dropout_7[0][0]']              \n","                                                                                                  \n"," tf.__operators__.add_7 (TFOpLa  (None, 500, 1)      0           ['conv1d_7[0][0]',               \n"," mbda)                                                            'tf.__operators__.add_6[0][0]'] \n","                                                                                                  \n"," global_average_pooling1d (Glob  (None, 500)         0           ['tf.__operators__.add_7[0][0]'] \n"," alAveragePooling1D)                                                                              \n","                                                                                                  \n"," dense (Dense)                  (None, 128)          64128       ['global_average_pooling1d[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," dropout_8 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n","                                                                                                  \n"," dense_1 (Dense)                (None, 2)            258         ['dropout_8[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 93,130\n","Trainable params: 93,130\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/200\n","45/45 [==============================] - 32s 477ms/step - loss: 0.9875 - sparse_categorical_accuracy: 0.5323 - val_loss: 0.7453 - val_sparse_categorical_accuracy: 0.5589\n","Epoch 2/200\n","45/45 [==============================] - 22s 480ms/step - loss: 0.8666 - sparse_categorical_accuracy: 0.5531 - val_loss: 0.6833 - val_sparse_categorical_accuracy: 0.5950\n","Epoch 3/200\n","45/45 [==============================] - 22s 489ms/step - loss: 0.7751 - sparse_categorical_accuracy: 0.5983 - val_loss: 0.6445 - val_sparse_categorical_accuracy: 0.6227\n","Epoch 4/200\n","45/45 [==============================] - 23s 510ms/step - loss: 0.7289 - sparse_categorical_accuracy: 0.6215 - val_loss: 0.6216 - val_sparse_categorical_accuracy: 0.6422\n","Epoch 5/200\n","45/45 [==============================] - 24s 540ms/step - loss: 0.6871 - sparse_categorical_accuracy: 0.6490 - val_loss: 0.6044 - val_sparse_categorical_accuracy: 0.6644\n","Epoch 6/200\n","45/45 [==============================] - 25s 553ms/step - loss: 0.6613 - sparse_categorical_accuracy: 0.6580 - val_loss: 0.5913 - val_sparse_categorical_accuracy: 0.6810\n","Epoch 7/200\n","45/45 [==============================] - 24s 534ms/step - loss: 0.6210 - sparse_categorical_accuracy: 0.6785 - val_loss: 0.5803 - val_sparse_categorical_accuracy: 0.6879\n","Epoch 8/200\n","45/45 [==============================] - 25s 547ms/step - loss: 0.6144 - sparse_categorical_accuracy: 0.6903 - val_loss: 0.5750 - val_sparse_categorical_accuracy: 0.6949\n","Epoch 9/200\n","45/45 [==============================] - 25s 551ms/step - loss: 0.5923 - sparse_categorical_accuracy: 0.7031 - val_loss: 0.5647 - val_sparse_categorical_accuracy: 0.7032\n","Epoch 10/200\n","45/45 [==============================] - 24s 545ms/step - loss: 0.5938 - sparse_categorical_accuracy: 0.6965 - val_loss: 0.5557 - val_sparse_categorical_accuracy: 0.7018\n","Epoch 11/200\n","45/45 [==============================] - 24s 539ms/step - loss: 0.5667 - sparse_categorical_accuracy: 0.7153 - val_loss: 0.5497 - val_sparse_categorical_accuracy: 0.7198\n","Epoch 12/200\n","45/45 [==============================] - 25s 552ms/step - loss: 0.5443 - sparse_categorical_accuracy: 0.7292 - val_loss: 0.5394 - val_sparse_categorical_accuracy: 0.7268\n","Epoch 13/200\n","45/45 [==============================] - 25s 551ms/step - loss: 0.5237 - sparse_categorical_accuracy: 0.7385 - val_loss: 0.5344 - val_sparse_categorical_accuracy: 0.7254\n","Epoch 14/200\n","45/45 [==============================] - 24s 541ms/step - loss: 0.5281 - sparse_categorical_accuracy: 0.7375 - val_loss: 0.5315 - val_sparse_categorical_accuracy: 0.7212\n","Epoch 15/200\n","45/45 [==============================] - 24s 546ms/step - loss: 0.5138 - sparse_categorical_accuracy: 0.7437 - val_loss: 0.5236 - val_sparse_categorical_accuracy: 0.7406\n","Epoch 16/200\n","45/45 [==============================] - 25s 548ms/step - loss: 0.5125 - sparse_categorical_accuracy: 0.7490 - val_loss: 0.5198 - val_sparse_categorical_accuracy: 0.7434\n","Epoch 17/200\n","45/45 [==============================] - 25s 549ms/step - loss: 0.4890 - sparse_categorical_accuracy: 0.7691 - val_loss: 0.5147 - val_sparse_categorical_accuracy: 0.7462\n","Epoch 18/200\n","45/45 [==============================] - 25s 550ms/step - loss: 0.4860 - sparse_categorical_accuracy: 0.7698 - val_loss: 0.5103 - val_sparse_categorical_accuracy: 0.7406\n","Epoch 19/200\n","11/45 [======>.......................] - ETA: 17s - loss: 0.4710 - sparse_categorical_accuracy: 0.7585"]}],"source":["input_shape = x_train.shape[1:]\n","\n","model = build_model(\n","    input_shape,\n","    head_size=256,\n","    num_heads=4,\n","    ff_dim=4,\n","    num_transformer_blocks=4,\n","    mlp_units=[128],\n","    mlp_dropout=0.4,\n","    dropout=0.25,\n",")\n","\n","model.compile(\n","    loss=\"sparse_categorical_crossentropy\",\n","    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n","    metrics=[\"sparse_categorical_accuracy\"],\n",")\n","model.summary()\n","\n","callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n","\n","model.fit(\n","    x_train,\n","    y_train,\n","    validation_split=0.2,\n","    epochs=200,\n","    batch_size=64,\n","    callbacks=callbacks,\n",")\n","\n","model.evaluate(x_test, y_test, verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"D93NFyM3P891"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":0}