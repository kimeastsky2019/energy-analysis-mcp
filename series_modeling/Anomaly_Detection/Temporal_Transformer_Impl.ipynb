{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/greatwhiz/tft_tf2.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myQSRnp4U1sq",
        "outputId": "be883bc0-6469-4a22-d622-5258200db0d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tft_tf2'...\n",
            "remote: Enumerating objects: 68, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 68 (delta 17), reused 16 (delta 16), pack-reused 44\u001b[K\n",
            "Unpacking objects: 100% (68/68), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r tft_tf2/* ."
      ],
      "metadata": {
        "id": "bVP5H1jEU6aD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import enum\n",
        "\n",
        "class InputTypes(enum.IntEnum):\n",
        "  \"\"\"Defines input types of each column.\"\"\"\n",
        "  TARGET = 0\n",
        "  OBSERVED_INPUT = 1\n",
        "  KNOWN_INPUT = 2\n",
        "  STATIC_INPUT = 3\n",
        "  ID = 4  # Single column used as an entity identifier\n",
        "  TIME = 5  # Single column exclusively used as a time index"
      ],
      "metadata": {
        "id": "xzNn_Cx59Imc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQrJ2ja58rGL"
      },
      "outputs": [],
      "source": [
        "# coding=utf-8\n",
        "# Copyright 2021 The Google Research Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "# Lint as: python3\n",
        "\"\"\"Temporal Fusion Transformer Model.\n",
        "Contains the full TFT architecture and associated components. Defines functions\n",
        "for training, evaluation and prediction using simple Pandas Dataframe inputs.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import gc\n",
        "import json\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "import libs.utils as utils\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "# Layer definitions.\n",
        "concat = tf.keras.backend.concatenate\n",
        "stack = tf.keras.backend.stack\n",
        "K = tf.keras.backend\n",
        "Add = tf.keras.layers.Add\n",
        "LayerNorm = tf.keras.layers.LayerNormalization\n",
        "Dense = tf.keras.layers.Dense\n",
        "Multiply = tf.keras.layers.Multiply\n",
        "Dropout = tf.keras.layers.Dropout\n",
        "Activation = tf.keras.layers.Activation\n",
        "Lambda = tf.keras.layers.Lambda\n",
        "\n",
        "# Default input types.\n",
        "# InputTypes = data_formatters.base.InputTypes\n",
        "\n",
        "\n",
        "# Layer utility functions.\n",
        "def linear_layer(size,\n",
        "                 activation=None,\n",
        "                 use_time_distributed=False,\n",
        "                 use_bias=True):\n",
        "    \"\"\"Returns simple Keras linear layer.\n",
        "    Args:\n",
        "      size: Output size\n",
        "      activation: Activation function to apply if required\n",
        "      use_time_distributed: Whether to apply layer across time\n",
        "      use_bias: Whether bias should be included in layer\n",
        "    \"\"\"\n",
        "    linear = tf.keras.layers.Dense(size, activation=activation, use_bias=use_bias)\n",
        "    if use_time_distributed:\n",
        "        linear = tf.keras.layers.TimeDistributed(linear)\n",
        "    return linear\n",
        "\n",
        "\n",
        "def apply_mlp(inputs,\n",
        "              hidden_size,\n",
        "              output_size,\n",
        "              output_activation=None,\n",
        "              hidden_activation='tanh',\n",
        "              use_time_distributed=False):\n",
        "    \"\"\"Applies simple feed-forward network to an input.\n",
        "    Args:\n",
        "      inputs: MLP inputs\n",
        "      hidden_size: Hidden state size\n",
        "      output_size: Output size of MLP\n",
        "      output_activation: Activation function to apply on output\n",
        "      hidden_activation: Activation function to apply on input\n",
        "      use_time_distributed: Whether to apply across time\n",
        "    Returns:\n",
        "      Tensor for MLP outputs.\n",
        "    \"\"\"\n",
        "    if use_time_distributed:\n",
        "        hidden = tf.keras.layers.TimeDistributed(\n",
        "            tf.keras.layers.Dense(hidden_size, activation=hidden_activation))(\n",
        "            inputs)\n",
        "        return tf.keras.layers.TimeDistributed(\n",
        "            tf.keras.layers.Dense(output_size, activation=output_activation))(\n",
        "            hidden)\n",
        "    else:\n",
        "        hidden = tf.keras.layers.Dense(\n",
        "            hidden_size, activation=hidden_activation)(\n",
        "            inputs)\n",
        "        return tf.keras.layers.Dense(\n",
        "            output_size, activation=output_activation)(\n",
        "            hidden)\n",
        "\n",
        "\n",
        "def apply_gating_layer(x,\n",
        "                       hidden_layer_size,\n",
        "                       dropout_rate=None,\n",
        "                       use_time_distributed=True,\n",
        "                       activation=None):\n",
        "    \"\"\"Applies a Gated Linear Unit (GLU) to an input.\n",
        "    Args:\n",
        "      x: Input to gating layer\n",
        "      hidden_layer_size: Dimension of GLU\n",
        "      dropout_rate: Dropout rate to apply if any\n",
        "      use_time_distributed: Whether to apply across time\n",
        "      activation: Activation function to apply to the linear feature transform if\n",
        "        necessary\n",
        "    Returns:\n",
        "      Tuple of tensors for: (GLU output, gate)\n",
        "    \"\"\"\n",
        "\n",
        "    if dropout_rate is not None:\n",
        "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    if use_time_distributed:\n",
        "        activation_layer = tf.keras.layers.TimeDistributed(\n",
        "            tf.keras.layers.Dense(hidden_layer_size, activation=activation))(\n",
        "            x)\n",
        "        gated_layer = tf.keras.layers.TimeDistributed(\n",
        "            tf.keras.layers.Dense(hidden_layer_size, activation='sigmoid'))(\n",
        "            x)\n",
        "    else:\n",
        "        activation_layer = tf.keras.layers.Dense(\n",
        "            hidden_layer_size, activation=activation)(\n",
        "            x)\n",
        "        gated_layer = tf.keras.layers.Dense(\n",
        "            hidden_layer_size, activation='sigmoid')(\n",
        "            x)\n",
        "\n",
        "    return tf.keras.layers.Multiply()([activation_layer,\n",
        "                                       gated_layer]), gated_layer\n",
        "\n",
        "\n",
        "def add_and_norm(x_list):\n",
        "    \"\"\"Applies skip connection followed by layer normalisation.\n",
        "    Args:\n",
        "      x_list: List of inputs to sum for skip connection\n",
        "    Returns:\n",
        "      Tensor output from layer.\n",
        "    \"\"\"\n",
        "    tmp = Add()(x_list)\n",
        "    tmp = LayerNorm()(tmp)\n",
        "    return tmp\n",
        "\n",
        "\n",
        "def gated_residual_network(x,\n",
        "                           hidden_layer_size,\n",
        "                           output_size=None,\n",
        "                           dropout_rate=None,\n",
        "                           use_time_distributed=True,\n",
        "                           additional_context=None,\n",
        "                           return_gate=False):\n",
        "    \"\"\"Applies the gated residual network (GRN) as defined in paper.\n",
        "    Args:\n",
        "      x: Network inputs\n",
        "      hidden_layer_size: Internal state size\n",
        "      output_size: Size of output layer\n",
        "      dropout_rate: Dropout rate if dropout is applied\n",
        "      use_time_distributed: Whether to apply network across time dimension\n",
        "      additional_context: Additional context vector to use if relevant\n",
        "      return_gate: Whether to return GLU gate for diagnostic purposes\n",
        "    Returns:\n",
        "      Tuple of tensors for: (GRN output, GLU gate)\n",
        "    \"\"\"\n",
        "\n",
        "    # Setup skip connection\n",
        "    if output_size is None:\n",
        "        output_size = hidden_layer_size\n",
        "        skip = x\n",
        "    else:\n",
        "        linear = Dense(output_size)\n",
        "        if use_time_distributed:\n",
        "            linear = tf.keras.layers.TimeDistributed(linear)\n",
        "        skip = linear(x)\n",
        "\n",
        "    # Apply feedforward network\n",
        "    hidden = linear_layer(\n",
        "        hidden_layer_size,\n",
        "        activation=None,\n",
        "        use_time_distributed=use_time_distributed)(\n",
        "        x)\n",
        "    if additional_context is not None:\n",
        "        hidden = hidden + linear_layer(\n",
        "            hidden_layer_size,\n",
        "            activation=None,\n",
        "            use_time_distributed=use_time_distributed,\n",
        "            use_bias=False)(\n",
        "            additional_context)\n",
        "    hidden = tf.keras.layers.Activation('elu')(hidden)\n",
        "    hidden = linear_layer(\n",
        "        hidden_layer_size,\n",
        "        activation=None,\n",
        "        use_time_distributed=use_time_distributed)(\n",
        "        hidden)\n",
        "\n",
        "    gating_layer, gate = apply_gating_layer(\n",
        "        hidden,\n",
        "        output_size,\n",
        "        dropout_rate=dropout_rate,\n",
        "        use_time_distributed=use_time_distributed,\n",
        "        activation=None)\n",
        "\n",
        "    if return_gate:\n",
        "        return add_and_norm([skip, gating_layer]), gate\n",
        "    else:\n",
        "        return add_and_norm([skip, gating_layer])\n",
        "\n",
        "\n",
        "# Attention Components.\n",
        "def get_decoder_mask(self_attn_inputs):\n",
        "    \"\"\"Returns causal mask to apply for self-attention layer.\n",
        "    Args:\n",
        "      self_attn_inputs: Inputs to self attention layer to determine mask shape\n",
        "    \"\"\"\n",
        "    len_s = tf.shape(input=self_attn_inputs)[1]\n",
        "    bs = tf.shape(input=self_attn_inputs)[:1]\n",
        "    mask = K.cumsum(tf.eye(len_s, batch_shape=bs), 1)\n",
        "    return mask\n",
        "\n",
        "\n",
        "class ScaledDotProductAttention():\n",
        "    \"\"\"Defines scaled dot product attention layer.\n",
        "    Attributes:\n",
        "      dropout: Dropout rate to use\n",
        "      activation: Normalisation function for scaled dot product attention (e.g.\n",
        "        softmax by default)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, attn_dropout=0.0):\n",
        "        self.dropout = Dropout(attn_dropout)\n",
        "        self.activation = Activation('softmax')\n",
        "\n",
        "    def __call__(self, q, k, v, mask):\n",
        "        \"\"\"Applies scaled dot product attention.\n",
        "        Args:\n",
        "          q: Queries\n",
        "          k: Keys\n",
        "          v: Values\n",
        "          mask: Masking if required -- sets softmax to very large value\n",
        "        Returns:\n",
        "          Tuple of (layer outputs, attention weights)\n",
        "        \"\"\"\n",
        "        temper = tf.sqrt(tf.cast(tf.shape(input=k)[-1], dtype='float32'))\n",
        "        attn = Lambda(lambda x: K.batch_dot(x[0], x[1], axes=[2, 2]) / temper)(\n",
        "            [q, k])  # shape=(batch, q, k)\n",
        "        if mask is not None:\n",
        "            mmask = Lambda(lambda x: (-1e+9) * (1. - K.cast(x, 'float32')))(\n",
        "                mask)  # setting to infinity\n",
        "            attn = Add()([attn, mmask])\n",
        "        attn = self.activation(attn)\n",
        "        attn = self.dropout(attn)\n",
        "        output = Lambda(lambda x: K.batch_dot(x[0], x[1]))([attn, v])\n",
        "        return output, attn\n",
        "\n",
        "\n",
        "class InterpretableMultiHeadAttention():\n",
        "    \"\"\"Defines interpretable multi-head attention layer.\n",
        "    Attributes:\n",
        "      n_head: Number of heads\n",
        "      d_k: Key/query dimensionality per head\n",
        "      d_v: Value dimensionality\n",
        "      dropout: Dropout rate to apply\n",
        "      qs_layers: List of queries across heads\n",
        "      ks_layers: List of keys across heads\n",
        "      vs_layers: List of values across heads\n",
        "      attention: Scaled dot product attention layer\n",
        "      w_o: Output weight matrix to project internal state to the original TFT\n",
        "        state size\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_head, d_model, dropout):\n",
        "        \"\"\"Initialises layer.\n",
        "        Args:\n",
        "          n_head: Number of heads\n",
        "          d_model: TFT state dimensionality\n",
        "          dropout: Dropout discard rate\n",
        "        \"\"\"\n",
        "\n",
        "        self.n_head = n_head\n",
        "        self.d_k = self.d_v = d_k = d_v = d_model // n_head\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.qs_layers = []\n",
        "        self.ks_layers = []\n",
        "        self.vs_layers = []\n",
        "\n",
        "        # Use same value layer to facilitate interp\n",
        "        vs_layer = Dense(d_v, use_bias=False)\n",
        "\n",
        "        for _ in range(n_head):\n",
        "            self.qs_layers.append(Dense(d_k, use_bias=False))\n",
        "            self.ks_layers.append(Dense(d_k, use_bias=False))\n",
        "            self.vs_layers.append(vs_layer)  # use same vs_layer\n",
        "\n",
        "        self.attention = ScaledDotProductAttention()\n",
        "        self.w_o = Dense(d_model, use_bias=False)\n",
        "\n",
        "    def __call__(self, q, k, v, mask=None):\n",
        "        \"\"\"Applies interpretable multihead attention.\n",
        "        Using T to denote the number of time steps fed into the transformer.\n",
        "        Args:\n",
        "          q: Query tensor of shape=(?, T, d_model)\n",
        "          k: Key of shape=(?, T, d_model)\n",
        "          v: Values of shape=(?, T, d_model)\n",
        "          mask: Masking if required with shape=(?, T, T)\n",
        "        Returns:\n",
        "          Tuple of (layer outputs, attention weights)\n",
        "        \"\"\"\n",
        "        n_head = self.n_head\n",
        "\n",
        "        heads = []\n",
        "        attns = []\n",
        "        for i in range(n_head):\n",
        "            qs = self.qs_layers[i](q)\n",
        "            ks = self.ks_layers[i](k)\n",
        "            vs = self.vs_layers[i](v)\n",
        "            head, attn = self.attention(qs, ks, vs, mask)\n",
        "\n",
        "            head_dropout = Dropout(self.dropout)(head)\n",
        "            heads.append(head_dropout)\n",
        "            attns.append(attn)\n",
        "        head = K.stack(heads) if n_head > 1 else heads[0]\n",
        "        attn = K.stack(attns)\n",
        "\n",
        "        outputs = K.mean(head, axis=0) if n_head > 1 else head\n",
        "        outputs = self.w_o(outputs)\n",
        "        outputs = Dropout(self.dropout)(outputs)  # output dropout\n",
        "\n",
        "        return outputs, attn\n",
        "\n",
        "\n",
        "class TFTDataCache(object):\n",
        "    \"\"\"Caches data for the TFT.\"\"\"\n",
        "\n",
        "    _data_cache = {}\n",
        "\n",
        "    @classmethod\n",
        "    def update(cls, data, key):\n",
        "        \"\"\"Updates cached data.\n",
        "        Args:\n",
        "          data: Source to update\n",
        "          key: Key to dictionary location\n",
        "        \"\"\"\n",
        "        cls._data_cache[key] = data\n",
        "\n",
        "    @classmethod\n",
        "    def get(cls, key):\n",
        "        \"\"\"Returns data stored at key location.\"\"\"\n",
        "        return cls._data_cache[key].copy()\n",
        "\n",
        "    @classmethod\n",
        "    def contains(cls, key):\n",
        "        \"\"\"Retuns boolean indicating whether key is present in cache.\"\"\"\n",
        "\n",
        "        return key in cls._data_cache\n",
        "\n",
        "\n",
        "# TFT model definitions.\n",
        "class TemporalFusionTransformer(object):\n",
        "    \"\"\"Defines Temporal Fusion Transformer.\n",
        "    Attributes:\n",
        "      name: Name of model\n",
        "      time_steps: Total number of input time steps per forecast date (i.e. Width\n",
        "        of Temporal fusion decoder N)\n",
        "      input_size: Total number of inputs\n",
        "      output_size: Total number of outputs\n",
        "      category_counts: Number of categories per categorical variable\n",
        "      n_multiprocessing_workers: Number of workers to use for parallel\n",
        "        computations\n",
        "      column_definition: List of tuples of (string, DataType, InputType) that\n",
        "        define each column\n",
        "      quantiles: Quantiles to forecast for TFT\n",
        "      use_cudnn: Whether to use Keras CuDNNLSTM or standard LSTM layers\n",
        "      hidden_layer_size: Internal state size of TFT\n",
        "      dropout_rate: Dropout discard rate\n",
        "      max_gradient_norm: Maximum norm for gradient clipping\n",
        "      learning_rate: Initial learning rate of ADAM optimizer\n",
        "      minibatch_size: Size of minibatches for training\n",
        "      num_epochs: Maximum number of epochs for training\n",
        "      early_stopping_patience: Maximum number of iterations of non-improvement\n",
        "        before early stopping kicks in\n",
        "      num_encoder_steps: Size of LSTM encoder -- i.e. number of past time steps\n",
        "        before forecast date to use\n",
        "      num_stacks: Number of self-attention layers to apply (default is 1 for basic\n",
        "        TFT)\n",
        "      num_heads: Number of heads for interpretable mulit-head attention\n",
        "      model: Keras model for TFT\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, raw_params, use_cudnn=False):\n",
        "        \"\"\"Builds TFT from parameters.\n",
        "        Args:\n",
        "          raw_params: Parameters to define TFT\n",
        "          use_cudnn: Whether to use CUDNN GPU optimised LSTM\n",
        "        \"\"\"\n",
        "\n",
        "        self.name = self.__class__.__name__\n",
        "\n",
        "        params = dict(raw_params)  # copy locally\n",
        "\n",
        "        # Data parameters\n",
        "        self.time_steps = int(params['total_time_steps'])\n",
        "        self.input_size = int(params['input_size'])\n",
        "        self.output_size = int(params['output_size'])\n",
        "        self.category_counts = json.loads(str(params['category_counts']))\n",
        "        self.n_multiprocessing_workers = int(params['multiprocessing_workers'])\n",
        "\n",
        "        # Relevant indices for TFT\n",
        "        self._input_obs_loc = json.loads(str(params['input_obs_loc'])) # unknown time series\n",
        "        self._static_input_loc = json.loads(str(params['static_input_loc']))\n",
        "        self._known_regular_input_idx = json.loads(\n",
        "            str(params['known_regular_inputs']))\n",
        "        self._known_categorical_input_idx = json.loads(\n",
        "            str(params['known_categorical_inputs']))\n",
        "\n",
        "        self.column_definition = params['column_definition']\n",
        "\n",
        "        # Network params\n",
        "        self.quantiles = [0.1, 0.5, 0.9]\n",
        "        self.use_cudnn = use_cudnn  # Whether to use GPU optimised LSTM\n",
        "        self.hidden_layer_size = int(params['hidden_layer_size'])\n",
        "        self.dropout_rate = float(params['dropout_rate'])\n",
        "        self.max_gradient_norm = float(params['max_gradient_norm'])\n",
        "        self.learning_rate = float(params['learning_rate'])\n",
        "        self.minibatch_size = int(params['minibatch_size'])\n",
        "        self.num_epochs = int(params['num_epochs'])\n",
        "        self.early_stopping_patience = int(params['early_stopping_patience'])\n",
        "\n",
        "        self.num_encoder_steps = int(params['num_encoder_steps'])\n",
        "        self.num_stacks = int(params['stack_size'])\n",
        "        self.num_heads = int(params['num_heads'])\n",
        "\n",
        "        # Serialisation options\n",
        "        self._temp_folder = os.path.join(params['model_folder'], 'tmp')\n",
        "        self.reset_temp_folder()\n",
        "\n",
        "        # Extra components to store Tensorflow nodes for attention computations\n",
        "        self._input_placeholder = None\n",
        "        self._attention_components = None\n",
        "        self._prediction_parts = None\n",
        "\n",
        "        print('*** {} params ***'.format(self.name))\n",
        "        for k in params:\n",
        "            print('# {} = {}'.format(k, params[k]))\n",
        "\n",
        "        # Build model\n",
        "        self.model = self.build_model()\n",
        "\n",
        "    def get_tft_embeddings(self, all_inputs):\n",
        "        \"\"\"Transforms raw inputs to embeddings.\n",
        "        Applies linear transformation onto continuous variables and uses embeddings\n",
        "        for categorical variables.\n",
        "        Args:\n",
        "          all_inputs: Inputs to transform\n",
        "        Returns:\n",
        "          Tensors for transformed inputs.\n",
        "        \"\"\"\n",
        "\n",
        "        time_steps = self.time_steps\n",
        "\n",
        "        # Sanity checks\n",
        "        for i in self._known_regular_input_idx:\n",
        "            if i in self._input_obs_loc:\n",
        "                raise ValueError('Observation cannot be known a priori!')\n",
        "        for i in self._input_obs_loc:\n",
        "            if i in self._static_input_loc:\n",
        "                raise ValueError('Observation cannot be static!')\n",
        "\n",
        "        if all_inputs.get_shape().as_list()[-1] != self.input_size:\n",
        "            raise ValueError(\n",
        "                'Illegal number of inputs! Inputs observed={}, expected={}'.format(\n",
        "                    all_inputs.get_shape().as_list()[-1], self.input_size))\n",
        "\n",
        "        num_categorical_variables = len(self.category_counts)\n",
        "        num_regular_variables = self.input_size - num_categorical_variables\n",
        "\n",
        "        embedding_sizes = [\n",
        "            self.hidden_layer_size for i, size in enumerate(self.category_counts)\n",
        "        ]\n",
        "\n",
        "        embeddings = []\n",
        "        for i in range(num_categorical_variables):\n",
        "            embedding = tf.keras.Sequential([\n",
        "                tf.keras.layers.InputLayer([time_steps]),\n",
        "                tf.keras.layers.Embedding(\n",
        "                    self.category_counts[i],\n",
        "                    embedding_sizes[i],\n",
        "                    input_length=time_steps,\n",
        "                    dtype=tf.float32)\n",
        "            ])\n",
        "            embeddings.append(embedding)\n",
        "\n",
        "        regular_inputs, categorical_inputs \\\n",
        "            = all_inputs[:, :, :num_regular_variables], \\\n",
        "              all_inputs[:, :, num_regular_variables:]\n",
        "\n",
        "        embedded_inputs = [\n",
        "            embeddings[i](categorical_inputs[Ellipsis, i])\n",
        "            for i in range(num_categorical_variables)\n",
        "        ]\n",
        "\n",
        "        # Static inputs\n",
        "        if self._static_input_loc:\n",
        "            static_inputs = [tf.keras.layers.Dense(self.hidden_layer_size)(\n",
        "                regular_inputs[:, 0, i:i + 1]) for i in range(num_regular_variables)\n",
        "                                if i in self._static_input_loc] \\\n",
        "                            + [embedded_inputs[i][:, 0, :]\n",
        "                               for i in range(num_categorical_variables)\n",
        "                               if i + num_regular_variables in self._static_input_loc]\n",
        "            static_inputs = tf.keras.backend.stack(static_inputs, axis=1)\n",
        "\n",
        "        else:\n",
        "            static_inputs = None\n",
        "\n",
        "        def convert_real_to_embedding(x):\n",
        "            \"\"\"Applies linear transformation for time-varying inputs.\"\"\"\n",
        "            return tf.keras.layers.TimeDistributed(\n",
        "                tf.keras.layers.Dense(self.hidden_layer_size))(\n",
        "                x)\n",
        "\n",
        "        # Targets\n",
        "        obs_inputs = tf.keras.backend.stack([\n",
        "            convert_real_to_embedding(regular_inputs[Ellipsis, i:i + 1])\n",
        "            for i in self._input_obs_loc\n",
        "        ],\n",
        "            axis=-1)\n",
        "\n",
        "        # Observed (a prioir unknown) inputs\n",
        "        wired_embeddings = []\n",
        "        for i in range(num_categorical_variables):\n",
        "            if i not in self._known_categorical_input_idx \\\n",
        "                    and i + num_regular_variables not in self._input_obs_loc:\n",
        "                e = embeddings[i](categorical_inputs[:, :, i])\n",
        "                wired_embeddings.append(e)\n",
        "\n",
        "        unknown_inputs = []\n",
        "        for i in range(regular_inputs.shape[-1]):\n",
        "            if i not in self._known_regular_input_idx \\\n",
        "                    and i not in self._input_obs_loc:\n",
        "                e = convert_real_to_embedding(regular_inputs[Ellipsis, i:i + 1])\n",
        "                unknown_inputs.append(e)\n",
        "\n",
        "        if unknown_inputs + wired_embeddings:\n",
        "            unknown_inputs = tf.keras.backend.stack(\n",
        "                unknown_inputs + wired_embeddings, axis=-1)\n",
        "        else:\n",
        "            unknown_inputs = None\n",
        "\n",
        "        # A priori known inputs\n",
        "        known_regular_inputs = [\n",
        "            convert_real_to_embedding(regular_inputs[Ellipsis, i:i + 1])\n",
        "            for i in self._known_regular_input_idx\n",
        "            if i not in self._static_input_loc\n",
        "        ]\n",
        "        known_categorical_inputs = [\n",
        "            embedded_inputs[i]\n",
        "            for i in self._known_categorical_input_idx\n",
        "            if i + num_regular_variables not in self._static_input_loc\n",
        "        ]\n",
        "\n",
        "        known_combined_layer = tf.keras.backend.stack(\n",
        "            known_regular_inputs + known_categorical_inputs, axis=-1)\n",
        "\n",
        "        return unknown_inputs, known_combined_layer, obs_inputs, static_inputs\n",
        "\n",
        "    def _get_single_col_by_type(self, input_type):\n",
        "        \"\"\"Returns name of single column for input type.\"\"\"\n",
        "\n",
        "        return utils.get_single_col_by_input_type(input_type,\n",
        "                                                  self.column_definition)\n",
        "\n",
        "    def training_data_cached(self):\n",
        "        \"\"\"Returns boolean indicating if training data has been cached.\"\"\"\n",
        "\n",
        "        return TFTDataCache.contains('train') and TFTDataCache.contains('valid')\n",
        "\n",
        "    def cache_batched_data(self, data, cache_key, num_samples=-1):\n",
        "        \"\"\"Batches and caches data once for using during training.\n",
        "        Args:\n",
        "          data: Data to batch and cache\n",
        "          cache_key: Key used for cache\n",
        "          num_samples: Maximum number of samples to extract (-1 to use all data)\n",
        "        \"\"\"\n",
        "\n",
        "        if num_samples > 0:\n",
        "            TFTDataCache.update(\n",
        "                self._batch_sampled_data(data, max_samples=num_samples), cache_key)\n",
        "        else:\n",
        "            TFTDataCache.update(self._batch_data(data), cache_key)\n",
        "\n",
        "        print('Cached data \"{}\" updated'.format(cache_key))\n",
        "\n",
        "    def _batch_sampled_data(self, data, max_samples):\n",
        "        \"\"\"Samples segments into a compatible format.\n",
        "        Args:\n",
        "          data: Sources data to sample and batch\n",
        "          max_samples: Maximum number of samples in batch\n",
        "        Returns:\n",
        "          Dictionary of batched data with the maximum samples specified.\n",
        "        \"\"\"\n",
        "\n",
        "        if max_samples < 1:\n",
        "            raise ValueError(\n",
        "                'Illegal number of samples specified! samples={}'.format(max_samples))\n",
        "\n",
        "        id_col = self._get_single_col_by_type(InputTypes.ID)\n",
        "        time_col = self._get_single_col_by_type(InputTypes.TIME)\n",
        "\n",
        "        data.sort_values(by=[id_col, time_col], inplace=True)\n",
        "\n",
        "        print('Getting valid sampling locations.')\n",
        "        valid_sampling_locations = []\n",
        "        split_data_map = {}\n",
        "        for identifier, df in data.groupby(id_col):\n",
        "            print('Getting locations for {}'.format(identifier))\n",
        "            num_entries = len(df)\n",
        "            if num_entries >= self.time_steps:\n",
        "                valid_sampling_locations += [\n",
        "                    (identifier, self.time_steps + i)\n",
        "                    for i in range(num_entries - self.time_steps + 1)\n",
        "                ]\n",
        "            split_data_map[identifier] = df\n",
        "\n",
        "        inputs = np.zeros((max_samples, self.time_steps, self.input_size))\n",
        "        outputs = np.zeros((max_samples, self.time_steps, self.output_size))\n",
        "        time = np.empty((max_samples, self.time_steps, 1), dtype=object)\n",
        "        identifiers = np.empty((max_samples, self.time_steps, 1), dtype=object)\n",
        "\n",
        "        if max_samples > 0 and len(valid_sampling_locations) > max_samples:\n",
        "            print('Extracting {} samples...'.format(max_samples))\n",
        "            ranges = [\n",
        "                valid_sampling_locations[i] for i in np.random.choice(\n",
        "                    len(valid_sampling_locations), max_samples, replace=False)\n",
        "            ]\n",
        "        else:\n",
        "            print('Max samples={} exceeds # available segments={}'.format(\n",
        "                max_samples, len(valid_sampling_locations)))\n",
        "            ranges = valid_sampling_locations\n",
        "\n",
        "        id_col = self._get_single_col_by_type(InputTypes.ID)\n",
        "        time_col = self._get_single_col_by_type(InputTypes.TIME)\n",
        "        target_col = self._get_single_col_by_type(InputTypes.TARGET)\n",
        "        input_cols = [\n",
        "            tup[0]\n",
        "            for tup in self.column_definition\n",
        "            if tup[2] not in {InputTypes.ID, InputTypes.TIME}\n",
        "        ]\n",
        "\n",
        "        for i, tup in enumerate(ranges):\n",
        "            if (i + 1 % 1000) == 0:\n",
        "                print(i + 1, 'of', max_samples, 'samples done...')\n",
        "            identifier, start_idx = tup\n",
        "            sliced = split_data_map[identifier].iloc[start_idx -\n",
        "                                                     self.time_steps:start_idx]\n",
        "            inputs[i, :, :] = sliced[input_cols]\n",
        "            outputs[i, :, :] = sliced[[target_col]]\n",
        "            time[i, :, 0] = sliced[time_col]\n",
        "            identifiers[i, :, 0] = sliced[id_col]\n",
        "\n",
        "        sampled_data = {\n",
        "            'inputs': inputs,\n",
        "            'outputs': outputs[:, self.num_encoder_steps:, :],\n",
        "            'active_entries': np.ones_like(outputs[:, self.num_encoder_steps:, :]),\n",
        "            'time': time,\n",
        "            'identifier': identifiers\n",
        "        }\n",
        "\n",
        "        return sampled_data\n",
        "\n",
        "    def _batch_data(self, data):\n",
        "        \"\"\"Batches data for training.\n",
        "        Converts raw dataframe from a 2-D tabular format to a batched 3-D array\n",
        "        to feed into Keras model.\n",
        "        Args:\n",
        "          data: DataFrame to batch\n",
        "        Returns:\n",
        "          Batched Numpy array with shape=(?, self.time_steps, self.input_size)\n",
        "        \"\"\"\n",
        "\n",
        "        # Functions.\n",
        "        def _batch_single_entity(input_data):\n",
        "            time_steps = len(input_data)\n",
        "            lags = self.time_steps\n",
        "            x = input_data.values\n",
        "            if time_steps >= lags:\n",
        "                return np.stack(\n",
        "                    [x[i:time_steps - (lags - 1) + i, :] for i in range(lags)], axis=1)\n",
        "\n",
        "            else:\n",
        "                return None\n",
        "\n",
        "        id_col = self._get_single_col_by_type(InputTypes.ID)\n",
        "        time_col = self._get_single_col_by_type(InputTypes.TIME)\n",
        "        target_col = self._get_single_col_by_type(InputTypes.TARGET)\n",
        "        input_cols = [\n",
        "            tup[0]\n",
        "            for tup in self.column_definition\n",
        "            if tup[2] not in {InputTypes.ID, InputTypes.TIME}\n",
        "        ]\n",
        "\n",
        "        data_map = {}\n",
        "        for _, sliced in data.groupby(id_col):\n",
        "\n",
        "            col_mappings = {\n",
        "                'identifier': [id_col],\n",
        "                'time': [time_col],\n",
        "                'outputs': [target_col],\n",
        "                'inputs': input_cols\n",
        "            }\n",
        "\n",
        "            for k in col_mappings:\n",
        "                cols = col_mappings[k]\n",
        "                arr = _batch_single_entity(sliced[cols].copy())\n",
        "\n",
        "                if k not in data_map:\n",
        "                    data_map[k] = [arr]\n",
        "                else:\n",
        "                    data_map[k].append(arr)\n",
        "\n",
        "        # Combine all data\n",
        "        for k in data_map:\n",
        "            data_map[k] = np.concatenate(data_map[k], axis=0)\n",
        "\n",
        "        # Shorten target so we only get decoder steps\n",
        "        data_map['outputs'] = data_map['outputs'][:, self.num_encoder_steps:, :]\n",
        "\n",
        "        active_entries = np.ones_like(data_map['outputs'])\n",
        "        if 'active_entries' not in data_map:\n",
        "            data_map['active_entries'] = active_entries\n",
        "        else:\n",
        "            data_map['active_entries'].append(active_entries)\n",
        "\n",
        "        return data_map\n",
        "\n",
        "    def _get_active_locations(self, x):\n",
        "        \"\"\"Formats sample weights for Keras training.\"\"\"\n",
        "        return (np.sum(x, axis=-1) > 0.0) * 1.0\n",
        "\n",
        "    def _build_base_graph(self):\n",
        "        \"\"\"Returns graph defining layers of the TFT.\"\"\"\n",
        "\n",
        "        # Size definitions.\n",
        "        time_steps = self.time_steps\n",
        "        combined_input_size = self.input_size\n",
        "        encoder_steps = self.num_encoder_steps\n",
        "\n",
        "        # Inputs.\n",
        "        all_inputs = tf.keras.layers.Input(\n",
        "            shape=(\n",
        "                time_steps,\n",
        "                combined_input_size,\n",
        "            ))\n",
        "\n",
        "        unknown_inputs, known_combined_layer, obs_inputs, static_inputs \\\n",
        "            = self.get_tft_embeddings(all_inputs)\n",
        "\n",
        "        # Isolate known and observed historical inputs.\n",
        "        if unknown_inputs is not None:\n",
        "            historical_inputs = concat([\n",
        "                unknown_inputs[:, :encoder_steps, :],\n",
        "                known_combined_layer[:, :encoder_steps, :],\n",
        "                obs_inputs[:, :encoder_steps, :]\n",
        "            ],\n",
        "                axis=-1)\n",
        "        else:\n",
        "            historical_inputs = concat([\n",
        "                known_combined_layer[:, :encoder_steps, :],\n",
        "                obs_inputs[:, :encoder_steps, :]\n",
        "            ],\n",
        "                axis=-1)\n",
        "\n",
        "        # Isolate only known future inputs.\n",
        "        future_inputs = known_combined_layer[:, encoder_steps:, :]\n",
        "\n",
        "        def static_combine_and_mask(embedding):\n",
        "            \"\"\"Applies variable selection network to static inputs.\n",
        "            Args:\n",
        "              embedding: Transformed static inputs\n",
        "            Returns:\n",
        "              Tensor output for variable selection network\n",
        "            \"\"\"\n",
        "\n",
        "            # Add temporal features\n",
        "            _, num_static, _ = embedding.get_shape().as_list()\n",
        "\n",
        "            flatten = tf.keras.layers.Flatten()(embedding)\n",
        "\n",
        "            # Nonlinear transformation with gated residual network.\n",
        "            mlp_outputs = gated_residual_network(\n",
        "                flatten,\n",
        "                self.hidden_layer_size,\n",
        "                output_size=num_static,\n",
        "                dropout_rate=self.dropout_rate,\n",
        "                use_time_distributed=False,\n",
        "                additional_context=None)\n",
        "\n",
        "            sparse_weights = tf.keras.layers.Activation('softmax')(mlp_outputs)\n",
        "            sparse_weights = K.expand_dims(sparse_weights, axis=-1)\n",
        "\n",
        "            trans_emb_list = []\n",
        "            for i in range(num_static):\n",
        "                e = gated_residual_network(\n",
        "                    embedding[:, i:i + 1, :],\n",
        "                    self.hidden_layer_size,\n",
        "                    dropout_rate=self.dropout_rate,\n",
        "                    use_time_distributed=False)\n",
        "                trans_emb_list.append(e)\n",
        "\n",
        "            transformed_embedding = concat(trans_emb_list, axis=1)\n",
        "\n",
        "            combined = tf.keras.layers.Multiply()(\n",
        "                [sparse_weights, transformed_embedding])\n",
        "\n",
        "            static_vec = K.sum(combined, axis=1)\n",
        "\n",
        "            return static_vec, sparse_weights\n",
        "\n",
        "        static_encoder, static_weights = static_combine_and_mask(static_inputs)\n",
        "\n",
        "        static_context_variable_selection = gated_residual_network(\n",
        "            static_encoder,\n",
        "            self.hidden_layer_size,\n",
        "            dropout_rate=self.dropout_rate,\n",
        "            use_time_distributed=False)\n",
        "        static_context_enrichment = gated_residual_network(\n",
        "            static_encoder,\n",
        "            self.hidden_layer_size,\n",
        "            dropout_rate=self.dropout_rate,\n",
        "            use_time_distributed=False)\n",
        "        static_context_state_h = gated_residual_network(\n",
        "            static_encoder,\n",
        "            self.hidden_layer_size,\n",
        "            dropout_rate=self.dropout_rate,\n",
        "            use_time_distributed=False)\n",
        "        static_context_state_c = gated_residual_network(\n",
        "            static_encoder,\n",
        "            self.hidden_layer_size,\n",
        "            dropout_rate=self.dropout_rate,\n",
        "            use_time_distributed=False)\n",
        "\n",
        "        def lstm_combine_and_mask(embedding):\n",
        "            \"\"\"Apply temporal variable selection networks.\n",
        "            Args:\n",
        "              embedding: Transformed inputs.\n",
        "            Returns:\n",
        "              Processed tensor outputs.\n",
        "            \"\"\"\n",
        "\n",
        "            # Add temporal features\n",
        "            _, time_steps, embedding_dim, num_inputs = embedding.get_shape().as_list()\n",
        "\n",
        "            flatten = K.reshape(embedding,\n",
        "                                [-1, time_steps, embedding_dim * num_inputs])\n",
        "\n",
        "            expanded_static_context = K.expand_dims(\n",
        "                static_context_variable_selection, axis=1)\n",
        "\n",
        "            # Variable selection weights\n",
        "            mlp_outputs, static_gate = gated_residual_network(\n",
        "                flatten,\n",
        "                self.hidden_layer_size,\n",
        "                output_size=num_inputs,\n",
        "                dropout_rate=self.dropout_rate,\n",
        "                use_time_distributed=True,\n",
        "                additional_context=expanded_static_context,\n",
        "  \n",
        "                return_gate=True)\n",
        "\n",
        "            sparse_weights = tf.keras.layers.Activation('softmax')(mlp_outputs)\n",
        "            sparse_weights = tf.expand_dims(sparse_weights, axis=2)\n",
        "\n",
        "            # Non-linear Processing & weight application\n",
        "            trans_emb_list = []\n",
        "            for i in range(num_inputs):\n",
        "                grn_output = gated_residual_network(\n",
        "                    embedding[Ellipsis, i],\n",
        "                    self.hidden_layer_size,\n",
        "                    dropout_rate=self.dropout_rate,\n",
        "                    use_time_distributed=True)\n",
        "                trans_emb_list.append(grn_output)\n",
        "\n",
        "            transformed_embedding = stack(trans_emb_list, axis=-1)\n",
        "\n",
        "            combined = tf.keras.layers.Multiply()(\n",
        "                [sparse_weights, transformed_embedding])\n",
        "            temporal_ctx = K.sum(combined, axis=-1)\n",
        "\n",
        "            return temporal_ctx, sparse_weights, static_gate\n",
        "\n",
        "        historical_features, historical_flags, _ = lstm_combine_and_mask(\n",
        "            historical_inputs)\n",
        "        future_features, future_flags, _ = lstm_combine_and_mask(future_inputs)\n",
        "\n",
        "        # LSTM layer\n",
        "        def get_lstm(return_state):\n",
        "            \"\"\"Returns LSTM cell initialized with default parameters.\"\"\"\n",
        "            if self.use_cudnn:\n",
        "                lstm = tf.compat.v1.keras.layers.CuDNNLSTM(\n",
        "                    self.hidden_layer_size,\n",
        "                    return_sequences=True,\n",
        "                    return_state=return_state,\n",
        "                    stateful=False,\n",
        "                )\n",
        "            else:\n",
        "                lstm = tf.keras.layers.LSTM(\n",
        "                    self.hidden_layer_size,\n",
        "                    return_sequences=True,\n",
        "                    return_state=return_state,\n",
        "                    stateful=False,\n",
        "                    # Additional params to ensure LSTM matches CuDNN, See TF 2.0 :\n",
        "                    # (https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM)\n",
        "                    activation='tanh',\n",
        "                    recurrent_activation='sigmoid',\n",
        "                    recurrent_dropout=0,\n",
        "                    unroll=False,\n",
        "                    use_bias=True)\n",
        "            return lstm\n",
        "\n",
        "        history_lstm, state_h, state_c \\\n",
        "            = get_lstm(return_state=True)(historical_features,\n",
        "                                          initial_state=[static_context_state_h,\n",
        "                                                         static_context_state_c])\n",
        "\n",
        "        future_lstm = get_lstm(return_state=False)(\n",
        "            future_features, initial_state=[state_h, state_c])\n",
        "\n",
        "        lstm_layer = concat([history_lstm, future_lstm], axis=1)\n",
        "\n",
        "        # Apply gated skip connection\n",
        "        input_embeddings = concat([historical_features, future_features], axis=1)\n",
        "\n",
        "        lstm_layer, _ = apply_gating_layer(\n",
        "            lstm_layer, self.hidden_layer_size, self.dropout_rate, activation=None)\n",
        "        temporal_feature_layer = add_and_norm([lstm_layer, input_embeddings])\n",
        "\n",
        "        # Static enrichment layers\n",
        "        expanded_static_context = K.expand_dims(static_context_enrichment, axis=1)\n",
        "        enriched, _ = gated_residual_network(\n",
        "            temporal_feature_layer,\n",
        "            self.hidden_layer_size,\n",
        "            dropout_rate=self.dropout_rate,\n",
        "            use_time_distributed=True,\n",
        "            additional_context=expanded_static_context,\n",
        "            return_gate=True)\n",
        "\n",
        "        # Decoder self attention\n",
        "        self_attn_layer = InterpretableMultiHeadAttention(\n",
        "            self.num_heads, self.hidden_layer_size, dropout=self.dropout_rate)\n",
        "\n",
        "        mask = get_decoder_mask(enriched)\n",
        "        x, self_att \\\n",
        "            = self_attn_layer(enriched, enriched, enriched,\n",
        "                              mask=mask)\n",
        "\n",
        "        x, _ = apply_gating_layer(\n",
        "            x,\n",
        "            self.hidden_layer_size,\n",
        "            dropout_rate=self.dropout_rate,\n",
        "            activation=None)\n",
        "        x = add_and_norm([x, enriched])\n",
        "\n",
        "        # Nonlinear processing on outputs\n",
        "        decoder = gated_residual_network(\n",
        "            x,\n",
        "            self.hidden_layer_size,\n",
        "            dropout_rate=self.dropout_rate,\n",
        "            use_time_distributed=True)\n",
        "\n",
        "        # Final skip connection\n",
        "        decoder, _ = apply_gating_layer(\n",
        "            decoder, self.hidden_layer_size, activation=None)\n",
        "        transformer_layer = add_and_norm([decoder, temporal_feature_layer])\n",
        "\n",
        "        # Attention components for explainability\n",
        "        attention_components = {\n",
        "            # Temporal attention weights\n",
        "            'decoder_self_attn': self_att,\n",
        "            # Static variable selection weights\n",
        "            'static_flags': static_weights[Ellipsis, 0],\n",
        "            # Variable selection weights of past inputs\n",
        "            'historical_flags': historical_flags[Ellipsis, 0, :],\n",
        "            # Variable selection weights of future inputs\n",
        "            'future_flags': future_flags[Ellipsis, 0, :]\n",
        "        }\n",
        "\n",
        "        return transformer_layer, all_inputs, attention_components\n",
        "\n",
        "    def build_model(self):\n",
        "        \"\"\"Build model and defines training losses.\n",
        "        Returns:\n",
        "          Fully defined Keras model.\n",
        "        \"\"\"\n",
        "\n",
        "        with tf.compat.v1.variable_scope(self.name):\n",
        "\n",
        "            transformer_layer, all_inputs, attention_components \\\n",
        "                = self._build_base_graph()\n",
        "\n",
        "            outputs = tf.keras.layers.TimeDistributed(\n",
        "                tf.keras.layers.Dense(self.output_size * len(self.quantiles))) \\\n",
        "                (transformer_layer[Ellipsis, self.num_encoder_steps:, :])\n",
        "\n",
        "            self._attention_components = attention_components\n",
        "\n",
        "            adam = tf.keras.optimizers.Adam(\n",
        "                learning_rate=self.learning_rate, clipnorm=self.max_gradient_norm)\n",
        "\n",
        "            model = tf.keras.Model(inputs=all_inputs, outputs=outputs)\n",
        "\n",
        "            print(model.summary())\n",
        "\n",
        "            valid_quantiles = self.quantiles\n",
        "            output_size = self.output_size\n",
        "\n",
        "            class QuantileLossCalculator(object):\n",
        "                \"\"\"Computes the combined quantile loss for prespecified quantiles.\n",
        "                Attributes:\n",
        "                  quantiles: Quantiles to compute losses\n",
        "                \"\"\"\n",
        "\n",
        "                def __init__(self, quantiles):\n",
        "                    \"\"\"Initializes computer with quantiles for loss calculations.\n",
        "                    Args:\n",
        "                      quantiles: Quantiles to use for computations.\n",
        "                    \"\"\"\n",
        "                    self.quantiles = quantiles\n",
        "\n",
        "                def quantile_loss(self, a, b):\n",
        "                    \"\"\"Returns quantile loss for specified quantiles.\n",
        "                    Args:\n",
        "                      a: Targets\n",
        "                      b: Predictions\n",
        "                    \"\"\"\n",
        "                    quantiles_used = set(self.quantiles)\n",
        "\n",
        "                    loss = 0.\n",
        "                    for i, quantile in enumerate(valid_quantiles):\n",
        "                        if quantile in quantiles_used:\n",
        "                            loss += utils.tensorflow_quantile_loss(\n",
        "                                a[Ellipsis, output_size * i:output_size * (i + 1)],\n",
        "                                b[Ellipsis, output_size * i:output_size * (i + 1)], quantile)\n",
        "                    return loss\n",
        "\n",
        "            quantile_loss = QuantileLossCalculator(valid_quantiles).quantile_loss\n",
        "\n",
        "            model.compile(\n",
        "                loss=quantile_loss, optimizer=adam, sample_weight_mode='temporal')\n",
        "\n",
        "            self._input_placeholder = all_inputs\n",
        "\n",
        "        return model\n",
        "\n",
        "    def fit(self, train_df=None, valid_df=None):\n",
        "        \"\"\"Fits deep neural network for given training and validation data.\n",
        "        Args:\n",
        "          train_df: DataFrame for training data\n",
        "          valid_df: DataFrame for validation data\n",
        "        \"\"\"\n",
        "\n",
        "        print('*** Fitting {} ***'.format(self.name))\n",
        "\n",
        "        # Add relevant callbacks\n",
        "        callbacks = [\n",
        "            tf.keras.callbacks.EarlyStopping(\n",
        "                monitor='val_loss',\n",
        "                patience=self.early_stopping_patience,\n",
        "                min_delta=1e-4),\n",
        "            tf.keras.callbacks.ModelCheckpoint(\n",
        "                filepath=self.get_keras_saved_path(self._temp_folder),\n",
        "                monitor='val_loss',\n",
        "                save_best_only=True,\n",
        "                save_weights_only=True),\n",
        "            tf.keras.callbacks.TerminateOnNaN()\n",
        "        ]\n",
        "\n",
        "        print('Getting batched_data')\n",
        "        if train_df is None:\n",
        "            print('Using cached training data')\n",
        "            train_data = TFTDataCache.get('train')\n",
        "        else:\n",
        "            train_data = self._batch_data(train_df)\n",
        "\n",
        "        if valid_df is None:\n",
        "            print('Using cached validation data')\n",
        "            valid_data = TFTDataCache.get('valid')\n",
        "        else:\n",
        "            valid_data = self._batch_data(valid_df)\n",
        "\n",
        "        print('Using keras standard fit')\n",
        "\n",
        "        def _unpack(data):\n",
        "            return data['inputs'], data['outputs'], \\\n",
        "                   self._get_active_locations(data['active_entries'])\n",
        "\n",
        "        # Unpack without sample weights\n",
        "        data, labels, active_flags = _unpack(train_data)\n",
        "        val_data, val_labels, val_flags = _unpack(valid_data)\n",
        "\n",
        "        all_callbacks = callbacks\n",
        "\n",
        "        self.model.fit(\n",
        "            x=data,\n",
        "            y=np.concatenate([labels, labels, labels], axis=-1),\n",
        "            sample_weight=active_flags,\n",
        "            epochs=self.num_epochs,\n",
        "            batch_size=self.minibatch_size,\n",
        "            validation_data=(val_data,\n",
        "                             np.concatenate([val_labels, val_labels, val_labels],\n",
        "                                            axis=-1), val_flags),\n",
        "            callbacks=all_callbacks,\n",
        "            shuffle=True,\n",
        "            use_multiprocessing=True,\n",
        "            workers=self.n_multiprocessing_workers)\n",
        "\n",
        "        # Load best checkpoint again\n",
        "        tmp_checkpont = self.get_keras_saved_path(self._temp_folder)\n",
        "        if os.path.exists(tmp_checkpont):\n",
        "            self.load(\n",
        "                self._temp_folder,\n",
        "                use_keras_loadings=True)\n",
        "\n",
        "        else:\n",
        "            print('Cannot load from {}, skipping ...'.format(self._temp_folder))\n",
        "\n",
        "    def evaluate(self, data=None, eval_metric='loss'):\n",
        "        \"\"\"Applies evaluation metric to the training data.\n",
        "        Args:\n",
        "          data: Dataframe for evaluation\n",
        "          eval_metric: Evaluation metic to return, based on model definition.\n",
        "        Returns:\n",
        "          Computed evaluation loss.\n",
        "        \"\"\"\n",
        "\n",
        "        if data is None:\n",
        "            print('Using cached validation data')\n",
        "            raw_data = TFTDataCache.get('valid')\n",
        "        else:\n",
        "            raw_data = self._batch_data(data)\n",
        "\n",
        "        inputs = raw_data['inputs']\n",
        "        outputs = raw_data['outputs']\n",
        "        active_entries = self._get_active_locations(raw_data['active_entries'])\n",
        "\n",
        "        metric_values = self.model.evaluate(\n",
        "            x=inputs,\n",
        "            y=np.concatenate([outputs, outputs, outputs], axis=-1),\n",
        "            sample_weight=active_entries,\n",
        "            workers=16,\n",
        "            use_multiprocessing=True)\n",
        "\n",
        "        metrics = pd.Series(metric_values, self.model.metrics_names)\n",
        "\n",
        "        return metrics[eval_metric]\n",
        "\n",
        "    def predict(self, df, return_targets=False):\n",
        "        \"\"\"Computes predictions for a given input dataset.\n",
        "        Args:\n",
        "          df: Input dataframe\n",
        "          return_targets: Whether to also return outputs aligned with predictions to\n",
        "            faciliate evaluation\n",
        "        Returns:\n",
        "          Input dataframe or tuple of (input dataframe, algined output dataframe).\n",
        "        \"\"\"\n",
        "\n",
        "        data = self._batch_data(df)\n",
        "\n",
        "        inputs = data['inputs']\n",
        "        time = data['time']\n",
        "        identifier = data['identifier']\n",
        "        outputs = data['outputs']\n",
        "\n",
        "        combined = self.model.predict(\n",
        "            inputs,\n",
        "            workers=16,\n",
        "            use_multiprocessing=True,\n",
        "            batch_size=self.minibatch_size)\n",
        "\n",
        "        # Format output_csv\n",
        "        if self.output_size != 1:\n",
        "            raise NotImplementedError('Current version only supports 1D targets!')\n",
        "\n",
        "        def format_outputs(prediction):\n",
        "            \"\"\"Returns formatted dataframes for prediction.\"\"\"\n",
        "\n",
        "            flat_prediction = pd.DataFrame(\n",
        "                prediction[:, :, 0],\n",
        "                columns=[\n",
        "                    't+{}'.format(i)\n",
        "                    for i in range(self.time_steps - self.num_encoder_steps)\n",
        "                ])\n",
        "            cols = list(flat_prediction.columns)\n",
        "            flat_prediction['forecast_time'] = time[:, self.num_encoder_steps - 1, 0]\n",
        "            flat_prediction['identifier'] = identifier[:, 0, 0]\n",
        "\n",
        "            # Arrange in order\n",
        "            return flat_prediction[['forecast_time', 'identifier'] + cols]\n",
        "\n",
        "        # Extract predictions for each quantile into different entries\n",
        "        process_map = {\n",
        "            'p{}'.format(int(q * 100)):\n",
        "                combined[Ellipsis, i * self.output_size:(i + 1) * self.output_size]\n",
        "            for i, q in enumerate(self.quantiles)\n",
        "        }\n",
        "\n",
        "        if return_targets:\n",
        "            # Add targets if relevant\n",
        "            process_map['targets'] = outputs\n",
        "\n",
        "        return {k: format_outputs(process_map[k]) for k in process_map}\n",
        "\n",
        "    def get_attention(self, df):\n",
        "        \"\"\"Computes TFT attention weights for a given dataset.\n",
        "        Args:\n",
        "          df: Input dataframe\n",
        "        Returns:\n",
        "            Dictionary of numpy arrays for temporal attention weights and variable\n",
        "              selection weights, along with their identifiers and time indices\n",
        "        \"\"\"\n",
        "\n",
        "        data = self._batch_data(df)\n",
        "        inputs = data['inputs']\n",
        "        identifiers = data['identifier']\n",
        "        time = data['time']\n",
        "\n",
        "        def get_batch_attention_weights(input_batch):\n",
        "            \"\"\"Returns weights for a given minibatch of data.\"\"\"\n",
        "            input_placeholder = self._input_placeholder\n",
        "            attention_weights = {}\n",
        "            for k in self._attention_components:\n",
        "                attention_weight = tf.compat.v1.keras.backend.get_session().run(\n",
        "                    self._attention_components[k],\n",
        "                    {input_placeholder: input_batch.astype(np.float32)})\n",
        "                attention_weights[k] = attention_weight\n",
        "            return attention_weights\n",
        "\n",
        "        # Compute number of batches\n",
        "        batch_size = self.minibatch_size\n",
        "        n = inputs.shape[0]\n",
        "        num_batches = n // batch_size\n",
        "        if n - (num_batches * batch_size) > 0:\n",
        "            num_batches += 1\n",
        "\n",
        "        # Split up inputs into batches\n",
        "        batched_inputs = [\n",
        "            inputs[i * batch_size:(i + 1) * batch_size, Ellipsis]\n",
        "            for i in range(num_batches)\n",
        "        ]\n",
        "\n",
        "        # Get attention weights, while avoiding large memory increases\n",
        "        attention_by_batch = [\n",
        "            get_batch_attention_weights(batch) for batch in batched_inputs\n",
        "        ]\n",
        "        attention_weights = {}\n",
        "        for k in self._attention_components:\n",
        "            attention_weights[k] = []\n",
        "            for batch_weights in attention_by_batch:\n",
        "                attention_weights[k].append(batch_weights[k])\n",
        "\n",
        "            if len(attention_weights[k][0].shape) == 4:\n",
        "                tmp = np.concatenate(attention_weights[k], axis=1)\n",
        "            else:\n",
        "                tmp = np.concatenate(attention_weights[k], axis=0)\n",
        "\n",
        "            del attention_weights[k]\n",
        "            gc.collect()\n",
        "            attention_weights[k] = tmp\n",
        "\n",
        "        attention_weights['identifiers'] = identifiers[:, 0, 0]\n",
        "        attention_weights['time'] = time[:, :, 0]\n",
        "\n",
        "        return attention_weights\n",
        "\n",
        "    # Serialisation.\n",
        "    def reset_temp_folder(self):\n",
        "        \"\"\"Deletes and recreates folder with temporary Keras training outputs.\"\"\"\n",
        "        print('Resetting temp folder...')\n",
        "        utils.create_folder_if_not_exist(self._temp_folder)\n",
        "        shutil.rmtree(self._temp_folder)\n",
        "        os.makedirs(self._temp_folder)\n",
        "\n",
        "    def get_keras_saved_path(self, model_folder):\n",
        "        \"\"\"Returns path to keras checkpoint.\"\"\"\n",
        "        return os.path.join(model_folder, '{}.check'.format(self.name))\n",
        "\n",
        "    def save(self, model_folder):\n",
        "        \"\"\"Saves optimal TFT weights.\n",
        "        Args:\n",
        "          model_folder: Location to serialze model.\n",
        "        \"\"\"\n",
        "        # Allows for direct serialisation of tensorflow variables to avoid spurious\n",
        "        # issue with Keras that leads to different performance evaluation results\n",
        "        # when model is reloaded (https://github.com/keras-team/keras/issues/4875).\n",
        "\n",
        "        utils.save(\n",
        "            tf.compat.v1.keras.backend.get_session(),\n",
        "            model_folder,\n",
        "            cp_name=self.name,\n",
        "            scope=self.name)\n",
        "\n",
        "    def load(self, model_folder, use_keras_loadings=False):\n",
        "        \"\"\"Loads TFT weights.\n",
        "        Args:\n",
        "          model_folder: Folder containing serialized models.\n",
        "          use_keras_loadings: Whether to load from Keras checkpoint.\n",
        "        Returns:\n",
        "        \"\"\"\n",
        "        if use_keras_loadings:\n",
        "            # Loads temporary Keras model saved during training.\n",
        "            serialisation_path = self.get_keras_saved_path(model_folder)\n",
        "            print('Loading model from {}'.format(serialisation_path))\n",
        "            self.model.load_weights(serialisation_path)\n",
        "        else:\n",
        "            # Loads tensorflow graph for optimal models.\n",
        "            utils.load(\n",
        "                tf.compat.v1.keras.backend.get_session(),\n",
        "                model_folder,\n",
        "                cp_name=self.name,\n",
        "                scope=self.name)\n",
        "\n",
        "    @classmethod\n",
        "    def get_hyperparm_choices(cls):\n",
        "        \"\"\"Returns hyperparameter ranges for random search.\"\"\"\n",
        "        return {\n",
        "            'dropout_rate': [0.1, 0.2, 0.3, 0.4, 0.5, 0.7, 0.9],\n",
        "            'hidden_layer_size': [10, 20, 40, 80, 160, 240, 320],\n",
        "            'minibatch_size': [64, 128, 256],\n",
        "            'learning_rate': [1e-4, 1e-3, 1e-2],\n",
        "            'max_gradient_norm': [0.01, 1.0, 100.0],\n",
        "            'num_heads': [1, 4],\n",
        "            'stack_size': [1],\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5FdeT4Tj8u0p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}